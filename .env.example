# Deepgram API Configuration
# Get your API key from https://console.deepgram.com/
DEEPGRAM_API_KEY=

# LocalAI Model Configuration
# Set these based on the models you've downloaded to ./models/
LOCALAI_WHISPER_MODEL=whisper-1
LOCALAI_LLM_MODEL=qwen2.5-7b

# LocalAI Backend Configuration
# External backends to pre-install (format: name:image,name:image)
# Examples for different GPU architectures:
#   CUDA 12: whisper:quay.io/go-skynet/local-ai-backends:latest-gpu-nvidia-cuda-12-whisper
#   CUDA 13: whisper:quay.io/go-skynet/local-ai-backends:latest-gpu-nvidia-cuda-13-whisper
#   CPU:     whisper:quay.io/go-skynet/local-ai-backends:latest-cpu-whisper
LOCALAI_EXTERNAL_BACKENDS=

# LocalAI Performance
# Number of parallel requests (reduce for lower memory usage)
LOCALAI_PARALLEL_REQUESTS=1
